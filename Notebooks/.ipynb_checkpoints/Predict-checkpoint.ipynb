{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "import xgboost as xgb\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device configuration (GPU can be enabled in settings)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_csv(\"../TrainTestDataFrames/train_concat.csv\")\n",
    "test_df = pd.read_csv(\"../../data/test.csv\")\n",
    "path = \"../../data/test/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional neural network\n",
    "class MyENet(nn.Module):\n",
    "    def __init__(self, Net):\n",
    "        super(MyENet, self).__init__()\n",
    "        self.Net = Net\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(1000, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def embedding(self, x):\n",
    "        out = self.Net(x)\n",
    "        return out \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Net(x)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "# First, load the EfficientNet with pre-trained parameters \n",
    "ENet = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "model = MyENet(ENet).to(device)\n",
    "model.load_state_dict(torch.load('../Models/ENetmodel.ckpt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>IP_6375035</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>IP_0589375</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                           NaN\n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity\n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso\n",
       "3  ISIC_0073313  IP_6375035  female        50.0                         torso\n",
       "4  ISIC_0073502  IP_0589375  female        45.0               lower extremity"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['sex', 'age_approx', 'anatom_site_general_challenge'] \n",
    "\n",
    "encoder = {}\n",
    "for feature in meta_features: \n",
    "    # determine unique features  \n",
    "    categories = np.unique(np.array(alldata[feature].values, str))\n",
    "    for i, category in enumerate(categories): \n",
    "        if category != 'nan':\n",
    "            encoder[category] = np.float(i)\n",
    "encoder['nan'] = np.nan\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path_to_files):\n",
    "        # 1. Initialize file paths or a list of file names.\n",
    "        self.path = path_to_files\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        \n",
    "        # load X \n",
    "        img_name = self.df['image_name'].values[index]\n",
    "        img_path = self.path + img_name + \".jpg\"\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        # determine meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # load y \n",
    "        #label = self.df[\"target\"].values[index]\n",
    "        #target = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        img = Image.fromarray(img)\n",
    "        #img = img.resize((256, 256))\n",
    "        img_processed = transform(img)\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return img_processed, meta_data, img_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total size of your dataset.\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.13 GiB already allocated; 10.38 MiB free; 3.19 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-89c0d5631674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.13 GiB already allocated; 10.38 MiB free; 3.19 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset(test_df, path)\n",
    "                                            \n",
    "batch_size = 16\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)   \n",
    "\n",
    "model = model.eval()\n",
    "for i, (images, meta_data, batch_image_names) in enumerate(test_loader):\n",
    "    \n",
    "    \n",
    "    images = images.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    embed = model.embedding(images)\n",
    "    nn_pred = model.output(embed).detach().cpu().numpy()\n",
    "    embedding = embed.detach().cpu().numpy()\n",
    "\n",
    "    # determine NN features for the set of images \n",
    "    batch_features = np.concatenate((embedding, meta_data.numpy(), nn_pred), axis=1)\n",
    "    \n",
    "    # append the dataset\n",
    "    try:\n",
    "        X = np.concatenate((X, batch_features), 0)\n",
    "        image_names = np.append(image_names, batch_image_names)\n",
    "    except:\n",
    "        X = batch_features \n",
    "        image_names = np.array(batch_image_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster({'nthread': 4})  # init model\n",
    "bst.load_model('../Models/xgbNN.model')  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtest = xgb.DMatrix(X)\n",
    "predictions = bst.predict(Dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission[\"image_name\"] = image_names \n",
    "submission[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"JT_submission_5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
