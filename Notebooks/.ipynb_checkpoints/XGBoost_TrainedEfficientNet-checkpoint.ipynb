{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device configuration (GPU can be enabled in settings)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 13609 images, validating on 1513 images.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"ENET_train_df.csv\")\n",
    "val_df = pd.read_csv(\"ENET_val_df.csv\")\n",
    "path = \"../../data-512/512x512-dataset-melanoma/512x512-dataset-melanoma/\"\n",
    "\n",
    "print(\"Training on {} images, validating on {} images.\".format(train_df.shape[0], val_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add training data on top of data that enet trained on: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40827 images, validating on 1513 images.\n"
     ]
    }
   ],
   "source": [
    "train_df_allsamples = pd.read_csv(\"../TrainTestDataFrames/marking.csv\") \n",
    "\n",
    "all_samples = train_df_allsamples['image_id'].values\n",
    "rm_samples = np.array(list(train_df['image_id'].values) + list(val_df['image_id'].values))\n",
    "\n",
    "inds = np.in1d(all_samples, rm_samples, invert=True)\n",
    "\n",
    "more_train = train_df_allsamples.iloc[inds, :].sample(n=2*train_df.shape[0])\n",
    "train_df = pd.concat((more_train, train_df)).sample(frac=1)\n",
    "print(\"Training on {} images, validating on {} images.\".format(train_df.shape[0], val_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, load the EfficientNet with pre-trained parameters \n",
    "ENet = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "\n",
    "# Convolutional neural network\n",
    "class MyENet(nn.Module):\n",
    "    def __init__(self, ENet):\n",
    "        super(MyENet, self).__init__()\n",
    "        # modify output layer of the pre-trained ENet \n",
    "        self.ENet = ENet\n",
    "        num_ftrs = self.ENet._fc.in_features\n",
    "        self.ENet._fc = nn.Linear(in_features=num_ftrs, out_features=512)\n",
    "        # map Enet output to melanoma decision \n",
    "        self.output = nn.Sequential(nn.BatchNorm1d(512),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Dropout(p=0.2),\n",
    "                                    nn.Linear(512, 1), \n",
    "                                    nn.Sigmoid())\n",
    "        \n",
    "    def embedding(self, x):\n",
    "        out = self.ENet(x)\n",
    "        return out \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.ENet(x)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "model = MyENet(ENet).to(device)\n",
    "# Load best model \n",
    "model.load_state_dict(torch.load('../Models/ENETmodel.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['sex', 'age_approx', 'anatom_site_general_challenge'] \n",
    "\n",
    "encoder = {}\n",
    "for feature in meta_features: \n",
    "    # determine unique features  \n",
    "    categories = np.unique(np.array(train_df[feature].values, str))\n",
    "    for i, category in enumerate(categories): \n",
    "        if category != 'nan':\n",
    "            encoder[category] = np.float(i)\n",
    "encoder['nan'] = np.nan\n",
    "\n",
    "# basic transform \n",
    "transform_1 = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.5, 1.0), ratio=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# no flip or rotation for test/validation data \n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(1.0, 1.0), ratio=(1.0, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "]) \n",
    "\n",
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path_to_files):\n",
    "        # 1. Initialize file paths or a list of file names.\n",
    "        self.path = path_to_files\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        \n",
    "        # load X \n",
    "        img_name = self.df['image_id'].values[index]\n",
    "        img_path = self.path + img_name + \".jpg\"\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        # determine meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # load y \n",
    "        label = self.df[\"target\"].values[index]\n",
    "        label_encode = np.zeros(2)\n",
    "        label_encode[label] = 1\n",
    "        target = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        img = Image.fromarray(img)\n",
    "        img_processed = transform_1(img)\n",
    "        \n",
    "        # 3. get meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        return img_processed, meta_data, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total size of your dataset.\n",
    "        return self.df.shape[0]\n",
    "\n",
    "class ValidDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path_to_files):\n",
    "        # 1. Initialize file paths or a list of file names.\n",
    "        self.path = path_to_files\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        \n",
    "        # load X \n",
    "        img_name = self.df['image_id'].values[index]\n",
    "        img_path = self.path + img_name + \".jpg\"\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        # determine meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # load y \n",
    "        label = self.df[\"target\"].values[index]\n",
    "        target = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        img = Image.fromarray(img)\n",
    "        img_processed = transform_valid(img)\n",
    "        \n",
    "        # 3. get meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return img_processed, meta_data, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total size of your dataset.\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [20:31<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use the data loader.\n",
    "\n",
    "batch_size = 12\n",
    "path = \"../../data-512/512x512-dataset-melanoma/512x512-dataset-melanoma/\"\n",
    "\n",
    "train_dataset = TrainDataset(train_df, path)                                               \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size)   \n",
    "\n",
    "model.eval()\n",
    "for i, (images, meta_data, labels) in enumerate(tqdm(train_loader)):\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    embed = model.embedding(images)\n",
    "    nn_pred = model.output(embed).detach().cpu().numpy()\n",
    "    embedding = embed.detach().cpu().numpy()\n",
    "\n",
    "    # determine NN features for the set of images \n",
    "    batch_features = np.concatenate((embedding, meta_data, nn_pred), axis=1)\n",
    "    \n",
    "    # append the dataset\n",
    "    try:\n",
    "        X = np.concatenate((X, batch_features), 0)\n",
    "        y = np.append(y, labels.numpy())\n",
    "    except:\n",
    "        X = batch_features \n",
    "        y = labels.numpy() \n",
    "        \n",
    "XGB_train_data = pd.DataFrame(data=X)\n",
    "XGB_train_data['targets'] = y \n",
    "XGB_train_data.to_csv(\"XGB_ENET_train.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X and y in pandas dataframe \n",
    "#XGB_train_data = pd.read_csv(\"XGB_ENET_train.csv\")\n",
    "#X = np.array(XGB_train_data.values[:, :-1], np.float32) \n",
    "#y = np.array(XGB_train_data['targets'].values, np.float32)\n",
    "\n",
    "mean_X = np.nanmean(X, 0)\n",
    "std_X = np.nanstd(X, 0)\n",
    "X_train_std = (X - mean_X) / std_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight positive examples more heavily \n",
    "def make_weights(targets):\n",
    "    nclasses = len(np.unique(targets))\n",
    "    count = [0] * nclasses                                                      \n",
    "    for label in targets:                                                         \n",
    "        count[np.int(label)] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(targets)                                              \n",
    "    for idx, label in enumerate(targets):                                          \n",
    "        weight[idx] = weight_per_class[np.int(label)]  \n",
    "        \n",
    "    return np.array(weight)/2\n",
    "\n",
    "# define function to fit and return xgboost model \n",
    "def fit_xgboost(X_train, y_train, X_val, y_val):\n",
    "    '''\n",
    "    # weight positive examples more heavily \n",
    "    w = make_weights(y_train)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, weight=w)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val) \n",
    "\n",
    "    # booster params \n",
    "    param = {'max_depth':16,\n",
    "            'learning_rate':0.02,\n",
    "            'subsample':0.8,\n",
    "            'eval_metric':'auc',\n",
    "            'objective': 'binary:logistic',\n",
    "            'nthread': 8}\n",
    "\n",
    "    # specify validation set \n",
    "    evallist = [(dval, 'eval')]\n",
    "\n",
    "    # Training \n",
    "    num_round = 5000\n",
    "    bst = xgb.train(param, dtrain, num_round, evals=evallist, early_stopping_rounds=10)\n",
    "    ''' \n",
    "    bst = xgb.XGBClassifier( \n",
    "        n_estimators=2000,  \n",
    "        max_depth=16,        \n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.2,\n",
    "        eval_metric='auc',\n",
    "        n_jobs = 8\n",
    "    )\n",
    "    \n",
    "    w = make_weights(y_train)\n",
    "    bst.fit(X_train, y_train, \n",
    "        sample_weight = w,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=10)\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:23<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "valid_dataset = ValidDataset(val_df, path)                                               \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, \n",
    "                                           batch_size=batch_size)   \n",
    "\n",
    "model = model.eval()\n",
    "for i, (images, meta_data, labels) in enumerate(tqdm(valid_loader)):\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    embed = model.embedding(images)\n",
    "    nn_pred = model.output(embed).detach().cpu().numpy()\n",
    "    embedding = embed.detach().cpu().numpy()\n",
    "\n",
    "    # determine NN features for the set of images \n",
    "    batch_features = np.concatenate((embedding, meta_data.numpy(), nn_pred), axis=1)\n",
    "    \n",
    "    # append the dataset\n",
    "    try:\n",
    "        X_test = np.concatenate((X_test, batch_features), 0)\n",
    "        y_test = np.append(y_test, labels.numpy())\n",
    "    except:\n",
    "        X_test = batch_features \n",
    "        y_test = labels.numpy() \n",
    "        \n",
    "XGB_data = pd.DataFrame(data=X_test)\n",
    "XGB_data['targets'] = y_test \n",
    "XGB_data.to_csv(\"XGB_ENET_val.csv\", index=False)\n",
    "\n",
    "#XGB_data = pd.read_csv(\"XGB_ENET_val.csv\")\n",
    "#X_test = np.array(XGB_data.values[:, :-1], np.float32) \n",
    "#y_test = np.array(XGB_data['targets'].values, np.float32)\n",
    "\n",
    "X_test_std = (X_test - mean_X) / std_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like stratified k-fold training and prediction is a very prominent strategy among high scoring models \n",
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits, shuffle=True)\n",
    "skf.get_n_splits(X_train_std, y)\n",
    "\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define \"out of fold\" set of predictions, represents validation performance  \n",
    "oof = np.zeros(len(X_train_std))\n",
    "ypred = np.zeros(len(X_test_std))\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train_std, y)):\n",
    "    \n",
    "    # get data partitions for Xtrain and Xval\n",
    "    X_train, X_val = X_train_std[train_index], X_train_std[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # train xgboost \n",
    "    bst = fit_xgboost(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # save out of fold predictions \n",
    "    #oof_pred = bst.predict(xgb.DMatrix(X_val))\n",
    "    probas = bst.predict_proba(X_val)\n",
    "    oof_pred = np.array([p[1] for p in probas])\n",
    "    oof[val_index] += oof_pred\n",
    "    \n",
    "    # save current model predictions on the true validation set \n",
    "    #test_pred = bst.predict(xgb.DMatrix(X_test_std))\n",
    "    probas = bst.predict_proba(X_test_std)\n",
    "    test_pred = np.array([p[1] for p in probas])\n",
    "    ypred += test_pred / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams.update({'font.size': 16, \n",
    "                     'legend.framealpha':1, \n",
    "                     'legend.edgecolor':'inherit'}) \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y, oof)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, \n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Train ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, ypred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, \n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = accuracy_score(y_test, np.round(ypred))\n",
    "print(\"validation accuracy: {:.3f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, np.round(X_test[:, -1])).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / len(y_test)\n",
    "# precision is the fraction of correctly identified positive samples\n",
    "# precision asks:\"Of all the samples identified as positives, how many were correct?\"\n",
    "precision = tp / (tp + fp)\n",
    "# recall is the ability of the model to identify positive samples \n",
    "# recall asks:\"Of all the positive samples in the dataset, how many were identified by the model?\"\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(\"CNN Stats:\")\n",
    "\n",
    "print(\"Model accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Model precision: {:.2f}\".format(precision))\n",
    "print(\"Model recall: {:.2f}\".format(recall))\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, np.round(X_test[:, -1])))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, np.round(ypred)).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / len(y_test)\n",
    "# precision is the fraction of correctly identified positive samples\n",
    "# precision asks:\"Of all the samples identified as positives, how many were correct?\"\n",
    "precision = tp / (tp + fp)\n",
    "# recall is the ability of the model to identify positive samples \n",
    "# recall asks:\"Of all the positive samples in the dataset, how many were identified by the model?\"\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(\"\\nXGBoost Stats:\")\n",
    "\n",
    "print(\"Model accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Model precision: {:.2f}\".format(precision))\n",
    "print(\"Model recall: {:.2f}\".format(recall))\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, np.round(ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams.update({'font.size': 16, \n",
    "                     'legend.framealpha':1, \n",
    "                     'legend.edgecolor':'inherit'}) \n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.hist(ypred, label='XGBoost')\n",
    "plt.hist(X_test[:, -1], label='CNN', alpha=.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#bst_feature_dict = bst.get_score(importance_type='gain')\n",
    "#feature_names = list(bst_feature_dict.keys())\n",
    "#feature_importance = [bst_feature_dict[key] for key in feature_names]\n",
    "feature_importance = bst.feature_importances_\n",
    "feature_names = ['f{}'.format(i+1) for i in range(len(feature_importance))]\n",
    "\n",
    "feature_names[-1] = 'NN pred'\n",
    "feature_names[-2] = 'Site'\n",
    "feature_names[-3] = 'Age'\n",
    "feature_names[-4] = 'Sex'\n",
    "\n",
    "feature_imp = pd.DataFrame()\n",
    "feature_imp['Feature'] = feature_names \n",
    "feature_imp['Value'] = feature_importance\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).iloc[:30])\n",
    "plt.title('XGB95 Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next try \"test time augmentation\" \n",
    "'''\n",
    "# \n",
    "transform_TTA = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.5, 1.0), ratio=(0.8, 1.2)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "class TTADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path_to_files):\n",
    "        # 1. Initialize file paths or a list of file names.\n",
    "        self.path = path_to_files\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        \n",
    "        # load X \n",
    "        img_name = self.df['image_id'].values[index]\n",
    "        img_path = self.path + img_name + \".jpg\"\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        # determine meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # load y \n",
    "        label = self.df[\"target\"].values[index]\n",
    "        target = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        img = Image.fromarray(img)\n",
    "        #img = img.resize((256, 256))\n",
    "        img_processed = transform_TTA(img)\n",
    "        \n",
    "        # 3. get meta data \n",
    "        meta = self.df[meta_features].values[index]\n",
    "        meta_data = np.array([encoder[str(m)] for m in meta])\n",
    "        \n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return img_processed, meta_data, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total size of your dataset.\n",
    "        return self.df.shape[0]\n",
    "\n",
    "N_TTA = 5\n",
    "batch_size = 1\n",
    "valid_dataset = TTADataset(val_df, path)                                               \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, \n",
    "                                           batch_size=batch_size)   \n",
    "\n",
    "ypred_TTA = np.zeros((len(ypred), N_TTA))\n",
    "\n",
    "model = model.eval()\n",
    "for j in range(N_TTA):\n",
    "    for i, (images, meta_data, labels) in enumerate(tqdm(valid_loader)):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        embed = model.embedding(images)\n",
    "        nn_pred = model.output(embed).detach().cpu().numpy()\n",
    "        embedding = embed.detach().cpu().numpy()\n",
    "\n",
    "        # determine NN features for the set of images \n",
    "        batch_features = np.concatenate((embedding, meta_data.numpy(), nn_pred), axis=1)\n",
    "\n",
    "        ypred_TTA[i, j] = bst.predict(xgb.DMatrix(batch_features))\n",
    "ypred_TTA_mean = np.mean(ypred_TTA, 1)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
